{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:42.273651900Z",
     "start_time": "2024-07-18T11:02:42.258653400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "max_iters = 1000\n",
    "# eval_interval = 2500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "['\\n', ' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—']\n"
     ]
    }
   ],
   "source": [
    "with open('The_wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(len(chars))\n",
    "vocab_size = len(chars)\n",
    "print(chars)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:43.633975600Z",
     "start_time": "2024-07-18T11:02:43.612871100Z"
    }
   },
   "id": "b8a21d66229a7912"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "#print(data[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:44.512196100Z",
     "start_time": "2024-07-18T11:02:44.462756600Z"
    }
   },
   "id": "bd71647246fedfa9"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[77, 12,  1,  3, 27, 73, 72,  1],\n",
      "        [ 1, 71, 57, 57, 71,  1, 54, 57],\n",
      "        [67, 71, 72,  1, 67, 74, 57, 70],\n",
      "        [67, 66, 57, 12,  1, 26, 58, 72]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[12,  1,  3, 27, 73, 72,  1, 34],\n",
      "        [71, 57, 57, 71,  1, 54, 57, 72],\n",
      "        [71, 72,  1, 67, 74, 57, 70, 10],\n",
      "        [66, 57, 12,  1, 26, 58, 72, 57]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "# print(x.shape)\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:45.190288100Z",
     "start_time": "2024-07-18T11:02:45.175460Z"
    }
   },
   "id": "d0bcb0251878fb8d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([45]) target is tensor(60)\n",
      "when input is tensor([45, 60]) target is tensor(57)\n",
      "when input is tensor([45, 60, 57]) target is tensor(1)\n",
      "when input is tensor([45, 60, 57,  1]) target is tensor(41)\n",
      "when input is tensor([45, 60, 57,  1, 41]) target is tensor(70)\n",
      "when input is tensor([45, 60, 57,  1, 41, 70]) target is tensor(67)\n",
      "when input is tensor([45, 60, 57,  1, 41, 70, 67]) target is tensor(62)\n",
      "when input is tensor([45, 60, 57,  1, 41, 70, 67, 62]) target is tensor(57)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print('when input is',context,'target is',target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:46.241739200Z",
     "start_time": "2024-07-18T11:02:46.216026Z"
    }
   },
   "id": "ec980d920d3d48f4"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:47.688239100Z",
     "start_time": "2024-07-18T11:02:47.672214400Z"
    }
   },
   "id": "7b2fda335a7f5841"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([103354,  65542, 120899,  60235])\n"
     ]
    }
   ],
   "source": [
    "ix = torch.randint(len(data)-block_size,(batch_size,))\n",
    "print(ix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:49.209195Z",
     "start_time": "2024-07-18T11:02:49.199421600Z"
    }
   },
   "id": "f045965e88117ca4"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dpM2O4llG?fEgci,SI*2PZR5!j-C(]N7Y\"C6pL0pFlw :MKw.Zk7goT[G)NyG6Wzk[Hn—a&Cp51\n",
      "*j'smgoN(*NT.0URbS\n",
      "4Lib;IVK;qHIp3Z.N!G?;QEJ;Il;sl2Twb8)58EwFG*WCsYO;2?k-orJBLgID4zkqu86GTCG?J1(8lcq 6p\n",
      "w-ySZf?r)N1ghF&9a0BM3p&Ee&k(*YDz02Fq\";.RJz0v*s*2,NZjlsK5 -1oZrxm5eHs'kNyOLU-m7qvCfC)OL02ZH]Q5YDg\"p;[a34Tnj\n",
      "j\n",
      "Px3p3jGn?1D..Q7GIS]9#C]8'E,rFK-WOT2w#JPHG?fm27z-Q558r*NRSJ\n",
      "y)ZKY76Sl8r2D!J:\n",
      "ew\"y!7:\n",
      "wL,z-dEm-)m 1vWOpZP)Vye!v—TG6drS&4lH254EIf957S\n",
      "-UD1e'vYR.#&t(ap[*N)5—4H!PzaY&-KvAH4w.4l#xNy1—v*2u72grlud4EAIO1&ZcH-[sQD8:EC&Q\n",
      "g,\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:57.742501Z",
     "start_time": "2024-07-18T11:02:57.467138400Z"
    }
   },
   "id": "bfdb4203485b80a3"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0,train_losses:4.845,val:4.870\n",
      "step:250,train_losses:4.775,val:4.807\n",
      "step:500,train_losses:4.705,val:4.731\n",
      "step:750,train_losses:4.643,val:4.674\n",
      "4.50199031829834\n"
     ]
    }
   ],
   "source": [
    "#create a pytorch optimiser\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    " \n",
    "for iter in range(max_iters):\n",
    "    \n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step:{iter},train_losses:{losses['train']:.3f},val:{losses['val']:.3f}\")\n",
    "        \n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    #evaluate the loss\n",
    "    logits,loss = model.forward(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())    \n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:03:27.246852300Z",
     "start_time": "2024-07-18T11:03:24.971322100Z"
    }
   },
   "id": "b423291e82356db4"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6NWUAJZ.idvzt'Slq?r*FY\"l0ru—Dk7]#irY—f(3Z7,OdHlK,6eSfrjq)(4)(*lDzk 1?fBYY0G*4Ts\n",
      "C\"oCZ.2Z.NWrwc]BZ.-0#go#J.gQFz#2\n",
      "2'V9a9al—G?Y#F58nfgIjVw3hwh)wnY&f3py#sugL(-1yf—5AH#goZpSAmQD![I#s9R.n&CeSNpTRJPC7lM—eGUgod]pDzWzl3;sdetV'WzP3#oIfpZwm]GYs.26Qllsk7cha!U1\n",
      "#(r-Mo[s0V8*N\"C1eBH\n",
      "w?;w#ojGH6NP[sArhf?p4HYm2JPMcsQbfBi\"?ws--1pdFA?fx8rELDzE1QtL(R?poQ4B57cV3g#Z9ONu])l,\"V;D1'sOE8OL((fe);4]M:2k]Qk8\"NP#2,Bm1gW1(gxWrpdFnaEngu\"gK(6)bSdo[xMe)N1Vh;s0F5*:LVyn,\n",
      "QRogoZG?fg-K4lL!.8\"V8JZ.Z\"c:jmkcIl.Y;GYLwwcwFxG*rAkcAvEa02]k\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
    "generate_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
    "print(generate_chars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:03:29.886672100Z",
     "start_time": "2024-07-18T11:03:29.658576200Z"
    }
   },
   "id": "46d645898f796281"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T11:02:20.856182400Z",
     "start_time": "2024-07-18T11:02:20.855184500Z"
    }
   },
   "id": "4f02c31469573e80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "cuda",
   "language": "python",
   "display_name": "cuda-gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
